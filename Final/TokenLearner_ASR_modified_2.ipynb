{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd40133",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dd40133",
    "outputId": "77b22d98-0834-475f-dd8e-327e075eab54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stan\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from keras_flops import get_flops\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "!set XLA_FLAGS=--xla_gpu_cuda_data_dir=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6beb0af",
   "metadata": {
    "id": "b6beb0af"
   },
   "outputs": [],
   "source": [
    "# DATA\n",
    "BATCH_SIZE = 64\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "#INPUT_SHAPE = (32, 32, 3)\n",
    "INPUT_SHAPE = (124, 129, 1)\n",
    "NUM_CLASSES = 8\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 20\n",
    "\n",
    "# AUGMENTATION\n",
    "IMAGE_SIZE = 64  # We will resize input images to this size.\n",
    "PATCH_SIZE = 8  # Size of the patches to be extracted from the input images.\n",
    "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
    "\n",
    "# ViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 8\n",
    "MLP_UNITS = [\n",
    "    PROJECTION_DIM * 2,\n",
    "    PROJECTION_DIM,\n",
    "]\n",
    "\n",
    "# TOKENLEARNER\n",
    "NUM_TOKENS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87a3f0",
   "metadata": {
    "id": "6c87a3f0"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61a9629",
   "metadata": {
    "id": "c61a9629"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data/mini_speech_commands'\n",
    "\n",
    "data_dir = pathlib.Path(DATASET_PATH)\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'mini_speech_commands.zip',\n",
    "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c62c0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21c62c0f",
    "outputId": "4c91f5b1-c678-4297-c63d-e6a3fc9269d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands: ['down' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "commands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\n",
    "print('Commands:', commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbabc585",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbabc585",
    "outputId": "fa965f8a-3656-4664-a722-2a7e99e11bf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 8 classes.\n",
      "Using 6400 files for training.\n",
      "Using 1600 files for validation.\n",
      "\n",
      "label names: ['down' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=data_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    output_sequence_length=16000,\n",
    "    subset='both')\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print()\n",
    "print(\"label names:\", label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ae3fcc",
   "metadata": {
    "id": "01ae3fcc"
   },
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "  audio = tf.squeeze(audio, axis=-1)\n",
    "  return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a00aa16",
   "metadata": {
    "id": "3a00aa16"
   },
   "outputs": [],
   "source": [
    "test_ds = val_ds.shard(num_shards=2, index=0)\n",
    "val_ds = val_ds.shard(num_shards=2, index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e9fba2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2e9fba2",
    "outputId": "25af2567-c890-4aa4-a73a-567b14162acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16000)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "for example_audio, example_labels in train_ds.take(1):  \n",
    "  print(example_audio.shape)\n",
    "  print(example_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f9f580",
   "metadata": {
    "id": "59f9f580"
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram\n",
    "\n",
    "def make_spec_ds(ds):\n",
    "  return ds.map(\n",
    "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def get_spectrogram(waveform, training=False):\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "    spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "    if training:\n",
    "        spectrogram = tfio.audio.freq_mask(spectrogram, param=10)\n",
    "        spectrogram = tfio.audio.time_mask(spectrogram, param=10)\n",
    "    # Obtain the magnitude of the STFT.\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    # Add a `channels` dimension, so that the spectrogram can be used\n",
    "    # as image-like input data with convolution layers (which expect\n",
    "    # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram\n",
    "\n",
    "def make_spec_ds(ds, training = False):\n",
    "    if training:\n",
    "        return ds.map(\n",
    "          map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        return ds.map(\n",
    "              map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "              num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd82c40",
   "metadata": {
    "id": "efd82c40"
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "test_spectrogram_ds = make_spec_ds(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f973b8",
   "metadata": {
    "id": "f2f973b8"
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
    "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decfa30a",
   "metadata": {
    "id": "decfa30a"
   },
   "outputs": [],
   "source": [
    "norm_layer = layers.Normalization()\n",
    "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        norm_layer,\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed612d9",
   "metadata": {
    "id": "0ed612d9"
   },
   "source": [
    "# Token Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "098fe17f",
   "metadata": {
    "id": "098fe17f"
   },
   "outputs": [],
   "source": [
    "def position_embedding(\n",
    "    projected_patches, num_patches=NUM_PATCHES, projection_dim=PROJECTION_DIM\n",
    "):\n",
    "    # Build the positions.\n",
    "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "\n",
    "    # Encode the positions with an Embedding layer.\n",
    "    encoded_positions = layers.Embedding(\n",
    "        input_dim=num_patches, output_dim=projection_dim\n",
    "    )(positions)\n",
    "\n",
    "    # Add encoded positions to the projected patches.\n",
    "    return projected_patches + encoded_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97735f81",
   "metadata": {
    "id": "97735f81"
   },
   "outputs": [],
   "source": [
    "def mlp(x, dropout_rate, hidden_units):\n",
    "    # Iterate over the hidden units and\n",
    "    # add Dense => Dropout.\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e99aa3",
   "metadata": {
    "id": "71e99aa3"
   },
   "outputs": [],
   "source": [
    "def token_learner(inputs, number_of_tokens=NUM_TOKENS):\n",
    "    # Layer normalize the inputs.\n",
    "    x = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(inputs)  # (B, H, W, C)\n",
    "\n",
    "    # Applying Conv2D => Reshape => Permute\n",
    "    # The reshape and permute is done to help with the next steps of\n",
    "    # multiplication and Global Average Pooling.\n",
    "    attention_maps = keras.Sequential(\n",
    "        [\n",
    "            # 3 layers of conv with gelu activation as suggested\n",
    "            # in the paper.\n",
    "            layers.Conv2D(\n",
    "                filters=number_of_tokens,\n",
    "                kernel_size=(3, 3),\n",
    "                activation=tf.nn.gelu,\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=number_of_tokens,\n",
    "                kernel_size=(3, 3),\n",
    "                activation=tf.nn.gelu,\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=number_of_tokens,\n",
    "                kernel_size=(3, 3),\n",
    "                activation=tf.nn.gelu,\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "            ),\n",
    "            # This conv layer will generate the attention maps\n",
    "            layers.Conv2D(\n",
    "                filters=number_of_tokens,\n",
    "                kernel_size=(3, 3),\n",
    "                activation=\"sigmoid\",  # Note sigmoid for [0, 1] output\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "            ),\n",
    "            # Reshape and Permute\n",
    "            layers.Reshape((-1, number_of_tokens)),  # (B, H*W, num_of_tokens)\n",
    "            layers.Permute((2, 1)),\n",
    "        ]\n",
    "    )(\n",
    "        x\n",
    "    )  # (B, num_of_tokens, H*W)\n",
    "\n",
    "    # Reshape the input to align it with the output of the conv block.\n",
    "    num_filters = inputs.shape[-1]\n",
    "    inputs = layers.Reshape((1, -1, num_filters))(inputs)  # inputs == (B, 1, H*W, C)\n",
    "\n",
    "    # Element-Wise multiplication of the attention maps and the inputs\n",
    "    attended_inputs = (\n",
    "        attention_maps[..., tf.newaxis] * inputs\n",
    "    )  # (B, num_tokens, H*W, C)\n",
    "\n",
    "    # Global average pooling the element wise multiplication result.\n",
    "    outputs = tf.reduce_mean(attended_inputs, axis=2)  # (B, num_tokens, C)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd17ca6",
   "metadata": {
    "id": "0bd17ca6"
   },
   "outputs": [],
   "source": [
    "def transformer(encoded_patches):\n",
    "    # Layer normalization 1.\n",
    "    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(encoded_patches)\n",
    "\n",
    "    # Multi Head Self Attention layer 1.\n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n",
    "    )(x1, x1)\n",
    "\n",
    "    # Skip connection 1.\n",
    "    x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "    # Layer normalization 2.\n",
    "    x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
    "\n",
    "    # MLP layer 1.\n",
    "    x4 = mlp(x3, hidden_units=MLP_UNITS, dropout_rate=0.1)\n",
    "\n",
    "    # Skip connection 2.\n",
    "    encoded_patches = layers.Add()([x4, x2])\n",
    "    return encoded_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "143d4949",
   "metadata": {
    "id": "143d4949"
   },
   "outputs": [],
   "source": [
    "def bottleneck_block(x, expand=64, squeeze=16):\n",
    "\n",
    "  m = keras.Sequential([\n",
    "      layers.Conv2D(expand, (1,1), padding='same'),\n",
    "      layers.BatchNormalization(),\n",
    "      layers.Activation('relu6'),\n",
    "      layers.DepthwiseConv2D((3,3), padding='same'),\n",
    "      layers.BatchNormalization(),\n",
    "      layers.Activation('relu6'),\n",
    "      layers.Conv2D(squeeze, (1,1), padding='same'),\n",
    "      layers.BatchNormalization()\n",
    "  ])(x)\n",
    "  return layers.Add()([m, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "872bb23a",
   "metadata": {
    "id": "872bb23a"
   },
   "outputs": [],
   "source": [
    "def create_vit_classifier(use_token_learner=True, token_learner_units=NUM_TOKENS):\n",
    "    inputs = layers.Input(shape=INPUT_SHAPE)  # (B, H, W, C)\n",
    "    \n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "\n",
    "    mbconv = bottleneck_block(augmented)\n",
    "    #mbconv = bottleneck_block(mbconv)\n",
    "    \n",
    "    # Create patches and project the pathces.\n",
    "    projected_patches = layers.Conv2D(\n",
    "        filters=PROJECTION_DIM,\n",
    "        kernel_size=(PATCH_SIZE, PATCH_SIZE),\n",
    "        strides=(PATCH_SIZE, PATCH_SIZE),\n",
    "        padding=\"VALID\",\n",
    "    )(mbconv)\n",
    "    \n",
    "    if use_token_learner:\n",
    "            projected_patches = token_learner(\n",
    "                projected_patches, token_learner_units\n",
    "            )\n",
    "            # _, hh, c = projected_patches.shape\n",
    "            # h = int(math.sqrt(hh))\n",
    "            # projected_patches = layers.Reshape((h, h, c))(\n",
    "            #     projected_patches)\n",
    "            # _, h, w, c = projected_patches.shape\n",
    "            # print(h,w,c)\n",
    "            # projected_patches = layers.Reshape((h * w, c))(\n",
    "            #     projected_patches\n",
    "            # )  # (B, number_patches, projection_dim)\n",
    "\n",
    "            # Add positional embeddings to the projected patches.\n",
    "            encoded_patches = position_embedding(\n",
    "                projected_patches, num_patches = NUM_TOKENS\n",
    "            )  # (B, number_patches, projection_dim)\n",
    "            encoded_patches = layers.Dropout(0.1)(encoded_patches)\n",
    "    else:\n",
    "        _, h, w, c = projected_patches.shape\n",
    "        print(h,w,c)\n",
    "        projected_patches = layers.Reshape((h * w, c))(\n",
    "            projected_patches\n",
    "        )  # (B, number_patches, projection_dim)\n",
    "\n",
    "        # Add positional embeddings to the projected patches.\n",
    "        encoded_patches = position_embedding(\n",
    "            projected_patches\n",
    "        )  # (B, number_patches, projection_dim)\n",
    "        encoded_patches = layers.Dropout(0.1)(encoded_patches)\n",
    "\n",
    "    # Iterate over the number of layers and stack up blocks of\n",
    "    # Transformer.\n",
    "    for i in range(NUM_LAYERS):\n",
    "        # Add a Transformer block.\n",
    "        encoded_patches = transformer(encoded_patches)\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e388bd8",
   "metadata": {
    "id": "8e388bd8"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    # Initialize the AdamW optimizer.\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    # Compile the model with the optimizer, loss function\n",
    "    # and the metrics.\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Define callbacks\n",
    "    checkpoint_filepath = \"./tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    # Custom Scheduler Function\n",
    "    lr_start   = 1e-4\n",
    "    lr_max     = 0.000015 * BATCH_SIZE\n",
    "    lr_min     = 1e-7\n",
    "    lr_ramp_ep = 3\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.7\n",
    "      \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "                \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "                \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "                \n",
    "        return lr\n",
    "\n",
    "\n",
    "    # Using this Custom Function, create a Callback\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "\n",
    "    # Train the model.\n",
    "    _ = model.fit(\n",
    "        train_spectrogram_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_spectrogram_ds,\n",
    "        callbacks=[lr_callback, checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_3_accuracy = model.evaluate(test_spectrogram_ds)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 3 accuracy: {round(top_3_accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f04c5217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Stan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "42852841\n",
      "8 8 128\n",
      "105232465\n"
     ]
    }
   ],
   "source": [
    "model = create_vit_classifier(use_token_learner=True)\n",
    "print(get_flops(model, batch_size=1))\n",
    "model = create_vit_classifier(use_token_learner=False)\n",
    "print(get_flops(model, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "274f07a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "274f07a4",
    "outputId": "fe3ac500-ac6f-4426-92b6-531996231151",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 22s 126ms/step - loss: 1.8876 - accuracy: 0.2881 - top-3-accuracy: 0.6152 - val_loss: 3.0323 - val_accuracy: 0.1562 - val_top-3-accuracy: 0.4167 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.00038666666666666667.\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 1.5687 - accuracy: 0.4191 - top-3-accuracy: 0.7653 - val_loss: 3.8437 - val_accuracy: 0.1445 - val_top-3-accuracy: 0.3659 - lr: 3.8667e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0006733333333333334.\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.1696 - accuracy: 0.5594 - top-3-accuracy: 0.8737 - val_loss: 4.0991 - val_accuracy: 0.1758 - val_top-3-accuracy: 0.3646 - lr: 6.7333e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8120 - accuracy: 0.7170 - top-3-accuracy: 0.9322 - val_loss: 2.8107 - val_accuracy: 0.2318 - val_top-3-accuracy: 0.5586 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.00067203.\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.5402 - accuracy: 0.8153 - top-3-accuracy: 0.9595 - val_loss: 3.0172 - val_accuracy: 0.4349 - val_top-3-accuracy: 0.6146 - lr: 6.7203e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000470451.\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.3813 - accuracy: 0.8662 - top-3-accuracy: 0.9727 - val_loss: 3.0882 - val_accuracy: 0.2904 - val_top-3-accuracy: 0.6589 - lr: 4.7045e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.00032934569999999995.\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2880 - accuracy: 0.9002 - top-3-accuracy: 0.9805 - val_loss: 2.3093 - val_accuracy: 0.5169 - val_top-3-accuracy: 0.7891 - lr: 3.2935e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.00023057198999999997.\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2287 - accuracy: 0.9206 - top-3-accuracy: 0.9837 - val_loss: 0.7508 - val_accuracy: 0.7643 - val_top-3-accuracy: 0.9440 - lr: 2.3057e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00016143039299999995.\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1843 - accuracy: 0.9395 - top-3-accuracy: 0.9855 - val_loss: 0.8068 - val_accuracy: 0.7682 - val_top-3-accuracy: 0.9336 - lr: 1.6143e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00011303127509999997.\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1606 - accuracy: 0.9467 - top-3-accuracy: 0.9869 - val_loss: 0.7434 - val_accuracy: 0.7956 - val_top-3-accuracy: 0.9362 - lr: 1.1303e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 7.915189256999997e-05.\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.1404 - accuracy: 0.9544 - top-3-accuracy: 0.9881 - val_loss: 1.0913 - val_accuracy: 0.7253 - val_top-3-accuracy: 0.9102 - lr: 7.9152e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 5.543632479899998e-05.\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.1259 - accuracy: 0.9592 - top-3-accuracy: 0.9884 - val_loss: 0.6289 - val_accuracy: 0.8268 - val_top-3-accuracy: 0.9531 - lr: 5.5436e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 3.883542735929998e-05.\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1199 - accuracy: 0.9613 - top-3-accuracy: 0.9894 - val_loss: 0.5026 - val_accuracy: 0.8672 - val_top-3-accuracy: 0.9674 - lr: 3.8835e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 2.7214799151509982e-05.\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.1153 - accuracy: 0.9630 - top-3-accuracy: 0.9892 - val_loss: 0.4959 - val_accuracy: 0.8620 - val_top-3-accuracy: 0.9727 - lr: 2.7215e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 1.908035940605699e-05.\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.1132 - accuracy: 0.9645 - top-3-accuracy: 0.9892 - val_loss: 0.5336 - val_accuracy: 0.8490 - val_top-3-accuracy: 0.9622 - lr: 1.9080e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 1.3386251584239891e-05.\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.1144 - accuracy: 0.9655 - top-3-accuracy: 0.9886 - val_loss: 0.5190 - val_accuracy: 0.8568 - val_top-3-accuracy: 0.9648 - lr: 1.3386e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 9.400376108967924e-06.\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.1154 - accuracy: 0.9631 - top-3-accuracy: 0.9886 - val_loss: 0.5162 - val_accuracy: 0.8555 - val_top-3-accuracy: 0.9674 - lr: 9.4004e-06\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 6.610263276277546e-06.\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.1153 - accuracy: 0.9631 - top-3-accuracy: 0.9891 - val_loss: 0.5451 - val_accuracy: 0.8516 - val_top-3-accuracy: 0.9622 - lr: 6.6103e-06\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 4.657184293394282e-06.\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.1225 - accuracy: 0.9634 - top-3-accuracy: 0.9878 - val_loss: 0.5342 - val_accuracy: 0.8503 - val_top-3-accuracy: 0.9622 - lr: 4.6572e-06\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 3.290029005375997e-06.\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.1254 - accuracy: 0.9606 - top-3-accuracy: 0.9894 - val_loss: 0.5154 - val_accuracy: 0.8594 - val_top-3-accuracy: 0.9661 - lr: 3.2900e-06\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.4328 - accuracy: 0.8666 - top-3-accuracy: 0.9796\n",
      "Test accuracy: 86.66%\n",
      "Test top 3 accuracy: 97.96%\n"
     ]
    }
   ],
   "source": [
    "vit_token_learner = create_vit_classifier()\n",
    "run_experiment(vit_token_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a25a9c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a25a9c6",
    "outputId": "80e12e3c-be6d-4d77-fbd3-5a460bdef273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 128\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 33s 250ms/step - loss: 2.0047 - accuracy: 0.2259 - top-3-accuracy: 0.5350 - val_loss: 3.5932 - val_accuracy: 0.1042 - val_top-3-accuracy: 0.3737 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.00038666666666666667.\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 1.4865 - accuracy: 0.4400 - top-3-accuracy: 0.7822 - val_loss: 2.5731 - val_accuracy: 0.2214 - val_top-3-accuracy: 0.5195 - lr: 3.8667e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0006733333333333334.\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.9339 - accuracy: 0.6617 - top-3-accuracy: 0.9131 - val_loss: 2.5640 - val_accuracy: 0.2812 - val_top-3-accuracy: 0.6250 - lr: 6.7333e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.6480 - accuracy: 0.7747 - top-3-accuracy: 0.9525 - val_loss: 2.5375 - val_accuracy: 0.3281 - val_top-3-accuracy: 0.7552 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.00067203.\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.4260 - accuracy: 0.8497 - top-3-accuracy: 0.9722 - val_loss: 1.0572 - val_accuracy: 0.6615 - val_top-3-accuracy: 0.8984 - lr: 6.7203e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000470451.\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.2968 - accuracy: 0.8933 - top-3-accuracy: 0.9837 - val_loss: 0.9413 - val_accuracy: 0.6992 - val_top-3-accuracy: 0.9284 - lr: 4.7045e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.00032934569999999995.\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.1973 - accuracy: 0.9356 - top-3-accuracy: 0.9892 - val_loss: 0.8093 - val_accuracy: 0.7604 - val_top-3-accuracy: 0.9518 - lr: 3.2935e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.00023057198999999997.\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.1446 - accuracy: 0.9520 - top-3-accuracy: 0.9916 - val_loss: 0.5906 - val_accuracy: 0.8190 - val_top-3-accuracy: 0.9518 - lr: 2.3057e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00016143039299999995.\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.1058 - accuracy: 0.9686 - top-3-accuracy: 0.9917 - val_loss: 0.5538 - val_accuracy: 0.8516 - val_top-3-accuracy: 0.9583 - lr: 1.6143e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00011303127509999997.\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0843 - accuracy: 0.9756 - top-3-accuracy: 0.9931 - val_loss: 0.4524 - val_accuracy: 0.8607 - val_top-3-accuracy: 0.9661 - lr: 1.1303e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 7.915189256999997e-05.\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0705 - accuracy: 0.9805 - top-3-accuracy: 0.9948 - val_loss: 0.4601 - val_accuracy: 0.8620 - val_top-3-accuracy: 0.9688 - lr: 7.9152e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 5.543632479899998e-05.\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0618 - accuracy: 0.9844 - top-3-accuracy: 0.9945 - val_loss: 0.4998 - val_accuracy: 0.8646 - val_top-3-accuracy: 0.9688 - lr: 5.5436e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 3.883542735929998e-05.\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0563 - accuracy: 0.9870 - top-3-accuracy: 0.9952 - val_loss: 0.4685 - val_accuracy: 0.8620 - val_top-3-accuracy: 0.9688 - lr: 3.8835e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 2.7214799151509982e-05.\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.0548 - accuracy: 0.9875 - top-3-accuracy: 0.9955 - val_loss: 0.4780 - val_accuracy: 0.8659 - val_top-3-accuracy: 0.9688 - lr: 2.7215e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 1.908035940605699e-05.\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0523 - accuracy: 0.9889 - top-3-accuracy: 0.9952 - val_loss: 0.4621 - val_accuracy: 0.8724 - val_top-3-accuracy: 0.9701 - lr: 1.9080e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 1.3386251584239891e-05.\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0543 - accuracy: 0.9881 - top-3-accuracy: 0.9958 - val_loss: 0.4529 - val_accuracy: 0.8750 - val_top-3-accuracy: 0.9727 - lr: 1.3386e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 9.400376108967924e-06.\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.0539 - accuracy: 0.9895 - top-3-accuracy: 0.9956 - val_loss: 0.4674 - val_accuracy: 0.8711 - val_top-3-accuracy: 0.9714 - lr: 9.4004e-06\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 6.610263276277546e-06.\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 0.0540 - accuracy: 0.9887 - top-3-accuracy: 0.9959 - val_loss: 0.4535 - val_accuracy: 0.8737 - val_top-3-accuracy: 0.9674 - lr: 6.6103e-06\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 4.657184293394282e-06.\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0556 - accuracy: 0.9886 - top-3-accuracy: 0.9955 - val_loss: 0.4577 - val_accuracy: 0.8724 - val_top-3-accuracy: 0.9701 - lr: 4.6572e-06\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 3.290029005375997e-06.\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0601 - accuracy: 0.9887 - top-3-accuracy: 0.9955 - val_loss: 0.4458 - val_accuracy: 0.8724 - val_top-3-accuracy: 0.9688 - lr: 3.2900e-06\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.4169 - accuracy: 0.8702 - top-3-accuracy: 0.9688\n",
      "Test accuracy: 87.02%\n",
      "Test top 3 accuracy: 96.88%\n"
     ]
    }
   ],
   "source": [
    "vit_token_learner = create_vit_classifier(use_token_learner=False)\n",
    "run_experiment(vit_token_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af662061",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af662061",
    "outputId": "0267a4cb-c7b7-40b5-cfc7-8707a0b48e94"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.python.profiler.model_analyzer import profile\n",
    "# from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n",
    "# print('TensorFlow:', tf.__version__)\n",
    "\n",
    "# model = create_vit_classifier(use_token_learner=True)\n",
    "\n",
    "# forward_pass = tf.function(\n",
    "#     model.call,\n",
    "#     input_signature=[tf.TensorSpec(shape=(1,) + model.input_shape[1:])])\n",
    "\n",
    "# graph_info = profile(forward_pass.get_concrete_function().graph,\n",
    "#                         options=ProfileOptionBuilder.float_operation())\n",
    "\n",
    "# # The //2 is necessary since `profile` counts multiply and accumulate\n",
    "# # as two flops, here we report the total number of multiply accumulate ops\n",
    "# flops = graph_info.total_float_ops // 2\n",
    "# print('Flops: {:,}'.format(flops))\n",
    "\n",
    "# model = create_vit_classifier(use_token_learner=False)\n",
    "\n",
    "# forward_pass = tf.function(\n",
    "#     model.call,\n",
    "#     input_signature=[tf.TensorSpec(shape=(1,) + model.input_shape[1:])])\n",
    "\n",
    "# graph_info = profile(forward_pass.get_concrete_function().graph,\n",
    "#                         options=ProfileOptionBuilder.float_operation())\n",
    "\n",
    "# # The //2 is necessary since `profile` counts multiply and accumulate\n",
    "# # as two flops, here we report the total number of multiply accumulate ops\n",
    "# flops = graph_info.total_float_ops // 2\n",
    "# print('Flops: {:,}'.format(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268732a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
